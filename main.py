# -*- coding: utf-8 -*-
"""Ignis_Scraping Assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N5TH5KWUyQApr_103jHUglAqQQGERPxA
"""

# import important libraries
import requests
from bs4 import BeautifulSoup
import pandas as pd

# Reading website link from text file
# inputFile = "/content/drive/MyDrive/internship/midwayusa.txt"
inputFile = "midwayusa.txt"
file1 = open(inputFile, 'r')
productLinks = file1.readlines()

products= []
for i in productLinks:
  print(i)


#function for scraping product link
def scrap(productLink):
  result = requests.get(productLink)
  src = result.content
  soup = BeautifulSoup(src, 'lxml')

  product = {}

  #scrapin product title
  Product_Title = soup.find('h1', attrs={'class': 'text-left heading-main'}).text.strip()
  #scrapin product availability status
  Product_Status = soup.find('span', attrs={'ng-bind': 'selector.productAvailability'}).text.strip()
  if (Product_Status == 'Available'):
    Product_Status = 'In Stock'
  elif (Product_Status == 'Mixed Availability'):
    Product_Status = 'Variant'
  else:
    Product_Status = 'Out of Stock'

  #putting all details in product dict
  product['Product_Title'] = Product_Title
  product['Product_Status'] = Product_Status
  product['productLink'] = productLink

  #appending to the list of productr details
  products.append(product)
  # printing the individual product details
  for key in product:
    print(key, ": ", product[key])
  
  print("\n")

# calling scrap function for each link present in file
for productLink in productLinks:
  #removing newline at the end of link
  productLink = productLink.split('\n')[0] 
  try:
    #handeling exception
    scrap(productLink)
  except:
    continue

# converting product details to pandas dataframe
df = pd.DataFrame.from_dict(products)
#converting dataframe into csv file
df.to_csv("output.csv")
df